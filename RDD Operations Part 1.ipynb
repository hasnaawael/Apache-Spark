{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c71d388a-6a7c-4733-8a9a-10353d9de93c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Transformations\n",
    "##### Map Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "931c6416-15bd-4307-95b5-df7b75b4b0e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = [1,2,3,4,5,6]\n",
    "rdd = sc.parallelize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "016c1792-1ecd-4589-8aa7-d976fafe7b48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####  1. map ###\nDescription: Return a new RDD by applying a function to all elements of this RDD.\n01 map example (multiply by 2): [2, 4, 6, 8, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "# 1. map\n",
    "print(\"#####  1. map ###\")\n",
    "print(\"Description: Return a new RDD by applying a function to all elements of this RDD.\")\n",
    "# Example 1: Multiply each element by 2\n",
    "simple_map = rdd.map(lambda x: x * 2).collect()\n",
    "print(\"01 map example (multiply by 2):\", simple_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e23e97f3-b2ee-4f43-ae11-7e6fe2a79c91",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example 2: Extract the length of each word in a list of sentences\n",
    "sentences = [\"Hello world\", \"Apache Spark\", \"RDD transformations Wide Vs Narrow Spark\"]\n",
    "sentences_rdd = sc.parallelize(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21ea6dbd-a622-4bcd-8b32-80d0043d783d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_map example (word count in sentences): [2, 2, 6]\n"
     ]
    }
   ],
   "source": [
    "words_map = sentences_rdd.map(lambda s: len(s.split(\" \"))).collect()\n",
    "print(\"example_map example (word count in sentences):\", words_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01113f6c-8b5d-4026-ae3c-5b02fb5500f8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Filter Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f637b2f-4ab1-4506-bf0b-ddaae8a0157c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 filter example (even numbers): [2, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "# 01 Example: Filter out even numbers\n",
    "simple_filter = rdd.filter(lambda x: x % 2 == 0).collect()\n",
    "print(\"01 filter example (even numbers):\", simple_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16905679-180d-428f-9819-643d7f0be95a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_ filter example (sentences with 'Spark'): ['Apache Spark', 'RDD transformations Wide Vs Narrow Spark']\n"
     ]
    }
   ],
   "source": [
    "# example_Example: Filter sentences containing the word 'Spark'\n",
    "words_filter = sentences_rdd.filter(lambda sentence: \"Spark\" in sentence).collect()\n",
    "print(\"example_ filter example (sentences with 'Spark'):\", words_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30220684-3991-48d9-8988-1b521915abd8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### FlatMap Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9e374e7-76ce-410c-97c1-3cfcceb59bac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "02 flatMap example (split sentences into words): ['Hello', 'world', 'Apache', 'Spark', 'RDD', 'transformations', 'Wide', 'Vs', 'Narrow', 'Spark']\n"
     ]
    }
   ],
   "source": [
    "# 3. flatMap\n",
    "simple_flatMap = sentences_rdd.flatMap(lambda sentence: sentence.split(\" \")).collect()\n",
    "print(\"02 flatMap example (split sentences into words):\", simple_flatMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65e7327a-ad48-45dd-bd73-b413031aec7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flatten_list  flatMap example (flatten list of lists): [1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# example_Example: Flatten a list of lists\n",
    "nested_lists = [[1, 2, 3], [4, 5], [6, 7, 8, 9]]\n",
    "nested_rdd = sc.parallelize(nested_lists)\n",
    "flatten_list = nested_rdd.flatMap(lambda x: x).collect()\n",
    "print(\"flatten_list  flatMap example (flatten list of lists):\", flatten_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e878d4e4-d136-42f4-be29-09106d406bae",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Reduce Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87e80675-5dca-4583-b31f-4966c917ce2a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01 reduce example (sum of elements): 21\n"
     ]
    }
   ],
   "source": [
    "# 4. reduce\n",
    "# 01 Example: Sum of elements\n",
    "simple_reduce = rdd.reduce(lambda x, y: x + y)\n",
    "print(\"01 reduce example (sum of elements):\", simple_reduce)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "579f89e0-e8f5-410e-b2ed-da4d2611f3f7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduce example (longest word): hippopotamus\n"
     ]
    }
   ],
   "source": [
    "# 02 Example: Find the longest word in a list of words\n",
    "words = [\"cat\", \"elephant\", \"rat\", \"hippopotamus\"]\n",
    "words_rdd = sc.parallelize(words)\n",
    "words_rdd_reduced = words_rdd.reduce(lambda x, y: x if len(x) > len(y) else y)\n",
    "print(\"reduce example (longest word):\", words_rdd_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9437327e-7a98-4494-8320-10028649bb4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### groupByKey Function\n",
    "**Definition**: GroupByKey collects all values associated with the same key into a single list.\n",
    "\n",
    "**Use Case**: Useful when you need to process or analyze all values for each key separately.\n",
    "\n",
    "**Efficiency**: Less efficient because it involves shuffling all values across the network and can result in high memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e4f1e14-8c92-41ad-a28e-35a30ae61917",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Group the values for each key in the RDD into a single sequence.\n01 groupByKey example (group numbers): [(1, ['a', 'ali']), (2, ['b']), (3, ['c']), (4, ['d']), (5, ['e'])]\n"
     ]
    }
   ],
   "source": [
    "# 5. groupByKey\n",
    "print(\"Description: Group the values for each key in the RDD into a single sequence.\")\n",
    "\n",
    "# 01 Example: Group numbers by even and odd\n",
    "pairs = [(1, 'a'),(1, 'ali'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e')]\n",
    "pairs_rdd = sc.parallelize(pairs)\n",
    "simple_groupByKey = pairs_rdd.groupByKey().mapValues(list).collect()\n",
    "print(\"01 groupByKey example (group numbers):\", simple_groupByKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b786c63-8684-4aa8-976e-189cf9fb23bc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words_grouped example (group words by starting letter): [('elephant', [5, 20]), ('dog', [3]), ('cat', [1]), ('car', [2]), ('deer', [4])]\n"
     ]
    }
   ],
   "source": [
    "# 02 Example: Group words by their starting letter\n",
    "words_pairs = [(\"cat\", 1), (\"car\", 2), (\"dog\", 3), (\"deer\", 4), (\"elephant\", 5),(\"elephant\", 20)]\n",
    "words_rdd = sc.parallelize(words_pairs)\n",
    "# mapValues(list) converts the grouped values (which are iterable) into lists.\n",
    "words_grouped = words_rdd.groupByKey().mapValues(list).collect()\n",
    "print(\"words_grouped example (group words by starting letter):\", words_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f489ab3-efa2-4895-8cd4-c99369a8d69e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### reduceByKey Function\n",
    "**Definition**: ReduceByKey combines values associated with the same key using a specified reduction function, resulting in a single value per key.\n",
    "\n",
    "**Use Case**: Ideal for operations that can aggregate values (like summing) and where intermediate results can be reduced locally before shuffling.\n",
    "\n",
    "**Efficiency**: More efficient due to local aggregation before shuffling, reducing network and memory overhead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bf7e54a-04f4-4203-83ce-c84a5592a1e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: Merge the values for each key using an associative and commutative reduce function.\n01 reduceByKey example (sum values by key): [(1, 'a_a'), (2, 'b_b'), (3, 'c'), (4, 'd'), (5, 'e')]\n"
     ]
    }
   ],
   "source": [
    "# 6. reduceByKey\n",
    "print(\"Description: Merge the values for each key using an associative and commutative reduce function.\")\n",
    "pairs = [(1, 'a'),(1, '_a'), (2, 'b'), (2, '_b'), (3, 'c'), (4, 'd'), (5, 'e')]\n",
    "pairs_rdd = sc.parallelize(pairs)\n",
    "\n",
    "# 01 Example: Sum values with the same key\n",
    "simple_reduceByKey = pairs_rdd.reduceByKey(lambda x, y: x + y).collect()\n",
    "print(\"01 reduceByKey example (sum values by key):\", simple_reduceByKey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d7552f50-7cb4-4950-8dd3-1a86672f3ecb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_ reduceByKey example (word count): [('elephant', 1), ('dog', 3), ('cat', 2)]\n"
     ]
    }
   ],
   "source": [
    "# example_Example: Count the occurrences of each word in a list\n",
    "word_list = [\"cat\", \"cat\", \"dog\", \"elephant\", \"dog\", \"dog\"]\n",
    "word_pairs_rdd = sc.parallelize(word_list).map(lambda word: (word, 1))\n",
    "example__reduceByKey = word_pairs_rdd.reduceByKey(lambda x, y: x + y).collect()\n",
    "print(\"example_ reduceByKey example (word count):\", example__reduceByKey)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "RDD Operations Part 1",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
